{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of frequently occurring scaffolds and fragments in the training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to understand whether structures are frequently occurring in interfering compounds. This could also help in predicting what type of molecules Reinvent will output and check how far the tool goes from the training chemical space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit.Chem import BRICS\n",
    "from rdkit import RDLogger\n",
    "\n",
    "from FtF.path import training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable rdkit logger for cleaner output\n",
    "RDLogger.DisableLog('rdApp.*') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(datadir):\n",
    "    \"\"\"\n",
    "    Data preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    # Load the data.\n",
    "    print(\"Loading data...\")\n",
    "    store_dataset = {}\n",
    "    for i in tqdm(os.listdir(datadir)):\n",
    "        if i.endswith(\".csv\") and \"fluo\" not in i:\n",
    "            fname = i.split(\".\")[0]\n",
    "            arr = pd.read_csv(str(datadir / i))\n",
    "            arr.columns = [\"SMILES\", \"Outcome\"]\n",
    "            store_dataset[fname] = arr[arr[\"Outcome\"] == 1]# Only keep the interfering compounds.\n",
    "    \n",
    "    return store_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 138.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 431.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Collect train and test positives\n",
    "training_data = preprocess_pipeline(training)\n",
    "testing_data = preprocess_pipeline(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analize Murcko scaffolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaffold(smile, include_chirality=False):\n",
    "    \"\"\"\n",
    "    Generate Murcko Scaffold per SMILES string.\n",
    "\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    scaffold = MurckoScaffold.MurckoScaffoldSmiles(mol=mol, includeChirality=include_chirality)\n",
    "    return scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaffolds_pipeline(dataset):\n",
    "    \"\"\"\n",
    "    Generating scaffolds for each dataset.    \n",
    "    \"\"\"\n",
    "    for key in dataset.keys():\n",
    "        dataset[key][\"Scaffold\"] = dataset[key][\"SMILES\"].apply(get_scaffold)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Murcko Scaffolds for the training and testing data.\n",
    "training_scaffolds = scaffolds_pipeline(training_data)\n",
    "testing_scaffolds = scaffolds_pipeline(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common scaffolds in fluc:\n",
      "O=C(Nc1ccccc1)c1ccccc1                 2\n",
      "c1ccc(C2COc3ccccc3C2)cc1               2\n",
      "c1cc(Oc2ccc3nc(NC4CCCCC4)sc3c2)ccn1    1\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 80\n",
      "\n",
      "\n",
      "Most common scaffolds in nluc:\n",
      "c1ccccc1                                                 2\n",
      "O=C(Nc1cnoc1-c1ccc(-c2ccccc2)cc1)OCc1ccccc1              2\n",
      "O=C(Nc1cccc(N2CCNCC2)c1)c1ccc(-c2ccc(-c3nnco3)cc2)cc1    2\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 69\n",
      "\n",
      "\n",
      "Most common scaffolds in redox:\n",
      "c1ccc2c(OC3CCCCO3)cccc2c1                                                             2\n",
      "C1CCC(OC2CCCOC2OC2COC(OC3CCC4C(CCC5C4CCC46OCC7(CCCCC74)CCC56)C3)C(OC3CCCCO3)C2)OC1    2\n",
      "O=C1C(=O)c2c(ccc3ccccc23)-c2occc21                                                    1\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 101\n",
      "\n",
      "\n",
      "Most common scaffolds in thiol:\n",
      "c1ccc(OC2CCCCO2)cc1          21\n",
      "C1=CC2CCCC2C(OC2CCCCO2)O1    12\n",
      "c1ccccc1                      6\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 724\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now check most common scaffolds in the training data.\n",
    "for key in training_scaffolds.keys():\n",
    "    print(f\"Most common scaffolds in {key}:\")\n",
    "    print(training_scaffolds[key][\"Scaffold\"].value_counts().head(3))\n",
    "    print(\"total scaffolds:\", training_scaffolds[key][\"Scaffold\"].value_counts().sum())\n",
    "    print(\"\\n\")\n",
    "    # Then draw the molecules in different subplots.\n",
    "    # Chem.Draw.MolsToGridImage([Chem.MolFromSmiles(i) for i in training_scaffolds[key][\"Scaffold\"].value_counts().head(3).index], molsPerRow=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common scaffolds in fluc:\n",
      "c1ccc(Nc2ccnc(Nc3ccccc3)n2)cc1    1\n",
      "c1ccc(-c2nc3ccccc3s2)cc1          1\n",
      "O=C(NCc1ccccc1)Nc1nccs1           1\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 14\n",
      "\n",
      "\n",
      "Most common scaffolds in nluc:\n",
      "c1ccc(-c2cc(OCc3ccccc3-n3cccn3)ncn2)cc1    1\n",
      "c1ccccc1                                   1\n",
      "c1ccc(Nc2ccc3ccccc3c2)cc1                  1\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 15\n",
      "\n",
      "\n",
      "Most common scaffolds in redox:\n",
      "C=C1CCCCC1=CC=C1CCCC2CCCC12                      2\n",
      "c1ccc(CCc2nc3cc(-c4cnoc4)ccc3n2CCN2CCOCC2)cc1    1\n",
      "O=C1OCC2C3=C(C(=O)c4occ1c42)C1CCC(=O)C1CC3       1\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 23\n",
      "\n",
      "\n",
      "Most common scaffolds in thiol:\n",
      "c1ccc(OC2CCCCO2)cc1                           8\n",
      "c1ccc(Nc2ccnc(Nc3ccc(N4CCNCC4)cc3)n2)cc1      2\n",
      "O=C(C=Cc1ccccc1)OC1CC2C=COC(OC3CCCCO3)C2C1    2\n",
      "Name: Scaffold, dtype: int64\n",
      "total scaffolds: 178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now check most common scaffolds in the test data.\n",
    "for key in training_scaffolds.keys():\n",
    "    print(f\"Most common scaffolds in {key}:\")\n",
    "    print(testing_scaffolds[key][\"Scaffold\"].value_counts().head(3))\n",
    "    print(\"total scaffolds:\", testing_scaffolds[key][\"Scaffold\"].value_counts().sum())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaffolds are very different between the training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frags(smile):\n",
    "    \"\"\"\n",
    "    Generate BRICS fragments per SMILES string.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    fragments = BRICS.BRICSDecompose(mol, minFragmentSize=3)\n",
    "    return fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragments_pipeline(dataset):\n",
    "    \"\"\"\n",
    "    Generating fragments for each dataset.\n",
    "    \"\"\"\n",
    "    for key in dataset.keys():\n",
    "        dataset[key][\"Fragments\"] = dataset[key][\"SMILES\"].apply(get_frags)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Fragments for the training and testing data.\n",
    "training_fragments = fragments_pipeline(training_data)\n",
    "testing_fragments = fragments_pipeline(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common fragments in fluc:\n",
      "[6*]C(=O)O              12\n",
      "[16*]c1ccc([16*])cc1    11\n",
      "[16*]c1ccccc1           11\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Most common fragments in nluc:\n",
      "[6*]C(=O)O              12\n",
      "[16*]c1ccccc1           11\n",
      "[16*]c1ccc([16*])cc1    11\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Most common fragments in redox:\n",
      "[1*]C(C)=O                  14\n",
      "[13*]C1OC(CO)C(O)C(O)C1O    13\n",
      "[3*]OC1OC(CO)C(O)C(O)C1O    13\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Most common fragments in thiol:\n",
      "[3*]OC1OC(CO)C(O)C(O)C1O        172\n",
      "[13*]C1OC(CO)C(O)C(O)C1O        167\n",
      "[3*]OCC1OC(O[3*])C(O)C(O)C1O     56\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now check most common fragments in the training data.\n",
    "for key in training_fragments.keys():\n",
    "    # Concatenate all the fragments sets.\n",
    "    all_frags = []\n",
    "    for i in training_fragments[key][\"Fragments\"]:\n",
    "        all_frags += i\n",
    "        # then count the fragments count for each set.\n",
    "    print(f\"Most common fragments in {key}:\")\n",
    "    print(pd.Series(all_frags).value_counts().head(3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common fragments in fluc:\n",
      "[5*]Nc1nccc([14*])n1    2\n",
      "[14*]c1ccnc([14*])n1    2\n",
      "[1*]C(=O)c1ccccn1       2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Most common fragments in nluc:\n",
      "[16*]c1ccccc1           5\n",
      "[6*]C(=O)O              4\n",
      "[16*]c1ccc([16*])cc1    3\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Most common fragments in redox:\n",
      "[13*]C1OC(CO)C(O)C(O)C1O    3\n",
      "[3*]OC1OC(CO)C(O)C(O)C1O    3\n",
      "[16*]c1ccc(OC)cc1           2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Most common fragments in thiol:\n",
      "[3*]OC1OC(CO)C(O)C(O)C1O    41\n",
      "[13*]C1OC(CO)C(O)C(O)C1O    38\n",
      "[16*]c1ccccc1               15\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now check most common fragments in the training data.\n",
    "for key in testing_fragments.keys():\n",
    "    # Concatenate all the fragments sets.\n",
    "    all_frags = []\n",
    "    for i in testing_fragments[key][\"Fragments\"]:\n",
    "        all_frags += i\n",
    "        # then count the fragments count for each set.\n",
    "    print(f\"Most common fragments in {key}:\")\n",
    "    print(pd.Series(all_frags).value_counts().head(3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
